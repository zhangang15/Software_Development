For this project, I create a web crawler that takes as input a seed URL to crawl and a query file. This program crawl all links found on the seed web page and resulting pages until all links have been crawled or have reached a maximum of 50 unique links. For each webpage crawled, this program removes all HTML tags and populates an inverted index from the resulting text. Finally, the program returns partial search results for each query in the supplied query file. This one still use multithreading for building and searching index.